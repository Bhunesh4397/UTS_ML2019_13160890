{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhunesh4397/UTS_ML2019_ID13160890/blob/master/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAXLJ_d9soEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKWGXb-UsrD0",
        "colab_type": "text"
      },
      "source": [
        "**Review Report on \"Generative Adversarial Nets\"**\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "**Content**\n",
        "    \n",
        "The concept of Generative Adversarial Networks (GANs) is proposed as a model which estimates the various frameworks of generative model using adversarial process. Generative models represents the actual probability distribution over the data the encountered in artificial intelligence algorithms. This is extended version of generative model which determines whether the sample is from model distribution or data distribution. GANs are able to produce data points by learning from data distribution which competes which discriminative model that can predict the actual source of data distribution. The main aim of generating this model is to reduce the probability of incorrect prediction by discriminative model where artificial data points more closer to the actual data points. This framework can yield speciÔ¨Åc training algorithms for many kinds of model and optimization algorithm. \n",
        "  \n",
        "In this paper, they explore the special case when the generative model generates samples by passing random noise through a multilayer perceptron, and the discriminative model is also a multilayer perceptron. These both models can be trained using only the highly successful backpropagation and dropout algorithms and sample from the generative model using only forward propagation. Generative Adversarial Networks encounters many issues with the prevailing generative model, but the most notable issue is being the intractability of some probability calculations which would then necessitate the use of less accurate approximations or Markov chains. This concern can be solved by Generative Adversarial Networks as there are no assumptions about the distribution of the data are made and the model instead learns through competition between the generative model and a discriminative model.\n",
        "\n",
        "\n",
        "**Innovation**\n",
        "\n",
        "The paper contributes to a new algorithms for developing generative models and able to overcome previous limitations of previous generative models. E.g. needing Markov chains for sampling, needing approximations for calculating actual distribution p(x) since it is intractable [1]. The technique can be applied to the same situations that previous generative models could be applied to. The paper does provide the groundwork for future innovations in the field. With GANs being a new method (at the time of publishing), there is plenty of exploration that can be done with GANs. Deep fakes are evidence of GANs being more than just a niche algorithm with limited applicability.\n",
        "  \n",
        "The research on GANs in the paper is extremely innovative for a multitude of reasons. The first reason is that GANs are able to overcome many of the limitations of other models. Previous generative models such as Deep Directed/Undirected Graphical Models were unable to calculate p(x), the probability distribution for the dataset. These models would need to rely on approximation methods to provide an estimate of p(x), which would hinder the quality of the training provided to the generative model. GANs do not need a representation of p(x) to be trained as the model is trained by a discriminative model instead. Previous generative models also relied on Markov chains to sample from the training data, which was computationally expensive. GANs reduce the computational power required for sampling by utilizing forward propagation, a feature of neural networks where an input passed through the network which, in the case of GANs is usually random noise, will be transformed into output by the nodes of the network. These computational advantages make GANs innovative as they expand the realm of possible problems that GANs can solve.\n",
        "\n",
        "**Technical quality**\n",
        "\n",
        "Overall the paper has a high level of technical quality. The theoretical underpinning of GANs was explained in detail and supported through the use of mathematical equations, proofs, and pseudocode, allowing for other fellow researchers to be able to not only gain a thorough understanding of how GANs work but also gives them the opportunity to identify any potential flaws or areas for improvement. While the authors of the paper don't delve too deep into how they set up their experiments, they have included a link to their code on Github. This is extremely useful for validating the reliability and replicability of the results achieved.\n",
        "\n",
        "However, there are a few issues that hamper the technical quality of the paper. One of these issues is the limited number of conducted experiments. Only 3 other generative models were used as comparisons and the experiments were limited to only 2 tests. This does, to some extent, bring into question the reliability of the results especially when taking into account that their evaluation method, which uses log-likelihood estimates, can often produce results with high variance. This choice was justified however, due to the absence of a better method for evaluation. The only other source of evaluation provided is a qualitative evaluation, which is not very useful as a qualitative evaluation can be very subjective. However, the authors state that the purpose of the qualitative evaluation is to only demonstrate that GANs are, at the bare minimum, competitive with current state-of-the-art generative models, not to provide a comparison.\n",
        "\n",
        "**Application And X-Factor**\n",
        "\n",
        "The authors do not discuss the application domain of GANs. However, it can be assumed that the application domain is no different from that of other generative models. Generative models are primarily useful for any problem in which data points, rather than predictions, must be outputted from the model, with the 'data points' representing images. Already GANs have proven their usefulness when applied to this set of problems. A rather infamous application of GANs is Deep Fakes, where convincing videos of celebrities were created and uploaded online. The amount of media attention generated by Deep is testament to the suitability of GANs for generating images or sequences of images. Deep Fakes have not only brought to light the power of GANs but also highlighted the potential for GANs to be used maliciously.\n",
        "\n",
        "GANs could also potentially be used for more artistic purposes. Since GANs have the ability to generate images that are in some way similar to training images, new pieces of art could be created that is based on a particular artstyle or even a combination of artstyles. In fact,the paper were able to demonstrate the ability of GANs to create facial images of anime characters. These images could also be used to provide inspiration to an artist, especially in cases where the generated images may not be of high quality.\n",
        "\n",
        "There are multiple directions that future research can take in order to further develop GANs. Future works could conduct research from an optimization perspective, where the research is focused on achieving performance increases. The authors have suggested that efficiency can be increased through the development of better methods for training the generative and discriminative model as well as better methods for sampling from the distribution. Further research could also develop variants of GANs such as conditional GANs, which add an extra input to the generative model such as a class label. \n",
        "\n",
        "**Presentation**\n",
        "\n",
        "The presentation of the paper is of a high standard of quality. The introduction and abstract provide a clear overview of what the paper is about without bombarding the reader with too much detail. The body of the paper contains plenty of depth and does not waste time discussing irrelevant points. Appropriate formatting is used for mathematical equations and pseudocode, and diagrams and graphs are provided in order to present a clearer view of certain concepts. The language used throughout the paper avoids being overly verbose. The only area that was lacking with regards to the presentation of the paper was the little explanation provided on the setup of the experiments, which leaves the reader confused about how they might replicate the experiment. Although there is a link to the source code, this link is provided in a small font at the footer of the first page which makes it easy to miss and there is no further mention of it throughout the paper.\n",
        "\n",
        "**References**\n",
        "\n",
        "Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A. and Bengio, Y., 2014. Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).\n",
        "\n",
        "Mirza, M. and Osindero, S., 2014. Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784.\n",
        "\n",
        "  \n",
        "\n"
      ]
    }
  ]
}